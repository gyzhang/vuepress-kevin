---
title: POC准备工作
date: 2024-10-29 23:16:29
permalink: /pages/63dbad/
categories: 
  - 工作
  - POC
tags: 
  - 
author: 
  name: Kevin Zhang
  link: https://github.com/gyzhang
---
# 麒麟V10SP3安装最新版本Docker

## 1 检查操作系统

安装操系统或在客户处检查操作系统的具体信息：

```bash
# 查看操作系统，Kylin-Server-V10-SP3-General-Release-2303-X86_64.iso
cat /etc/kylin-release
# 查看系统构架
uname -p
arch
```

在本地 POC 演练的时候，安装虚拟机后：

```bash
vi /etc/ssh/sshd_config
# 113行，去掉注释：UseDNS no
# 关闭防火墙
systemctl disable firewalld
```

## 2 复制虚拟机

复制虚拟机后，需要重置虚拟机的 ID、主机名和 IP 地址：

```bash
hostnamectl set-hostname docker
rm -f /etc/machine-id
systemd-machine-id-setup
# 修改ip地址
nmtui
```

## 3 提取 Docker

通过模拟 CentOS 8 来提取 Docker（26.1.3）离线安装文件：

```bash
# 添加阿里云的docker ce安装源
dnf config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 
# 为安装源修改麒麟V10SP3的发行版本号：对应的CentOS是8版本
echo "8" > /etc/yum/vars/centos_version
sed -i 's/$releasever/$centos_version/g' /etc/yum.repos.d/docker-ce.repo
sed -i 's/$releasever/$centos_version/g' /etc/yum.repos.d/kylin_x86_64.repo
dnf clean packages
# 下载
mkdir -p /root/docker-26.1.3-kylin-v10sp3
dnf install docker-ce docker-ce-cli docker-compose-plugin --downloadonly --downloaddir=/root/docker-26.1.3-kylin-v10sp3
# 打包备份
tar -czvf docker-26.1.3-kylin-v10sp3-x86_64.tar.gz ./docker-26.1.3-kylin-v10sp3/
```

（可选）提取 K8s 安装文件：

```bash
vi /etc/yum.repos.d/kubernetes.repo
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/rpm/
enabled=1
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.30/rpm/repodata/repomd.xml.key
<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<

mkdir -p /root/k8s-1.30.3-kylin-v10sp3
dnf install -y kubeadm-1.30.3 kubectl-1.30.3 kubelet-1.30.3 --downloadonly --downloaddir=/root/k8s-1.30.3-kylin-v10sp3

cd /root/
tar -czvf k8s-1.30.3-kylin-v10sp3-x86_64.tar.gz ./k8s-1.30.3-kylin-v10sp3/

dnf -y localinstall /root/k8s-1.30.3-kylin-v10sp3/*.rpm
```

## 4 离线安装 Docker

在没有网络的机器上离线安装 Docker，可以将离线安装包发送给客户，以 root 用户的权限进行安装：

```bash
# 麒麟V10SP3最小默认安装后，不用做任何修改即可安装Docker
tar -xzvf docker-26.1.3-kylin-v10sp3-x86_64.tar.gz
cd /root/docker-26.1.3-kylin-v10sp3
# 如果没有网络，连dnf都运行不了，就用rpm -ivh *.rpm
dnf -y localinstall *.rpm
# 开机自启动docker
systemctl enable docker
# 重启服务器
reboot
# 检查安装结果
systemctl status docker
docker --version
docker compose version
```

## 5 基础运行环境

基础运行环境依赖好几个中间件服务，离线拉取镜像文件，并保存备份：

```bash
# MySQL
docker pull mysql:8.4.2-oracle
docker save mysql:8.4.2-oracle -o /root/images/mysql-8.4.2-oracle.tar
# ES
docker pull docker.elastic.co/elasticsearch/elasticsearch:7.10.2
docker save docker.elastic.co/elasticsearch/elasticsearch:7.10.2 -o /root/images/elasticsearch-7.10.2.tar
# OceanBase社区版
docker pull --platform linux/amd64 oceanbase/oceanbase-ce:4.2.1.
docker save oceanbase/oceanbase-ce:4.2.1 -o /root/images/oceanbase-ce-4.2.1.tar
```

恢复长沙服务器上的 TDSQL 数据（`20240903-信贷2.0演示数据脚本-长沙机房TDSQL导出+收拾完字符编码+经MySQL和OceanBase正确导入验证.zip`：可导入 MySQL 和 OceanBase），整理后的数据脚本为 `ncpm2-mysql-db-script.tar.gz`，上传到 `/root/docker/script/mysql/` 后解压并将 *.sql 存放到 `/root/docker/script/mysql/` 目录：

```bash
mkdir -p /root/docker/script/mysql
cd /root/docker/script/mysql
tar -xzvf ncpm2-mysql-db-script.tar.gz
mv ./ncpm2/*.sql .
rm -rf ncpm2*
```

上述备份的数据库文件和脚本，对应如下的 docker compose 脚本，经测试其数据恢复（22 个数据库）时间为 5 分钟左右：

```yaml
services:
  mysql:
    image: mysql:8.4.2-oracle
    container_name: ncpm2-mysql
    restart: on-failure:3
    environment:
      - MYSQL_ROOT_PASSWORD=Kevin@GoodMan998
    command: --max_connections=4000 --lower_case_table_names=1
    volumes:
      - "/root/docker/data/mysql:/var/lib/mysql"
      - "/root/docker/script/mysql/1001-ijep8_sys_pro.sql:/docker-entrypoint-initdb.d/1001.sql:ro"
      - "/root/docker/script/mysql/1002-ijep8_priv_pro.sql:/docker-entrypoint-initdb.d/1002.sql:ro"
      - "/root/docker/script/mysql/1003-ijep8_bpm_pro.sql:/docker-entrypoint-initdb.d/1003.sql:ro"
      - "/root/docker/script/mysql/1004-ijep8_sch_pro.sql:/docker-entrypoint-initdb.d/1004.sql:ro"
      - "/root/docker/script/mysql/1005-ijep8_demo_pro.sql:/docker-entrypoint-initdb.d/1005.sql:ro"
      - "/root/docker/script/mysql/1101-gcb_account_pro.sql:/docker-entrypoint-initdb.d/1101.sql:ro"
      - "/root/docker/script/mysql/1102-gcb_afterloan_pro.sql:/docker-entrypoint-initdb.d/1102.sql:ro"
      - "/root/docker/script/mysql/1103-gcb_assess_pro.sql:/docker-entrypoint-initdb.d/1103.sql:ro"
      - "/root/docker/script/mysql/1104-gcb_collateral_pro.sql:/docker-entrypoint-initdb.d/1104.sql:ro"
      - "/root/docker/script/mysql/1105-gcb_contract_pro.sql:/docker-entrypoint-initdb.d/1105.sql:ro"
      - "/root/docker/script/mysql/1106-gcb_credit_pro.sql:/docker-entrypoint-initdb.d/1106.sql:ro"
      - "/root/docker/script/mysql/1107-gcb_customer_pro.sql:/docker-entrypoint-initdb.d/1107.sql:ro"
      - "/root/docker/script/mysql/1108-gcb_decision_pro.sql:/docker-entrypoint-initdb.d/1108.sql:ro"
      - "/root/docker/script/mysql/1109-gcb_guarantee_pro.sql:/docker-entrypoint-initdb.d/1109.sql:ro"
      - "/root/docker/script/mysql/1110-gcb_intellcenter_pro.sql:/docker-entrypoint-initdb.d/1110.sql:ro"
      - "/root/docker/script/mysql/1111-gcb_intellconfig_pro.sql:/docker-entrypoint-initdb.d/1111.sql:ro"
      - "/root/docker/script/mysql/1112-gcb_loan_pro.sql:/docker-entrypoint-initdb.d/1112.sql:ro"
      - "/root/docker/script/mysql/1113-gcb_product_pro.sql:/docker-entrypoint-initdb.d/1113.sql:ro"
      - "/root/docker/script/mysql/1114-gcb_quota_pro.sql:/docker-entrypoint-initdb.d/1114.sql:ro"
      - "/root/docker/script/mysql/1115-gcb_report_pro.sql:/docker-entrypoint-initdb.d/1115.sql:ro"
      - "/root/docker/script/mysql/1116-gcb_reportmock_pro.sql:/docker-entrypoint-initdb.d/1116.sql:ro"
      - "/root/docker/script/mysql/1201-dadp43.sql:/docker-entrypoint-initdb.d/1201.sql:ro"
    healthcheck:
      test: mysql -h 127.0.0.1 -u root --password=Kevin@GoodMan998 -e "SELECT * FROM ijep8_sys_pro.sys_user ORDER BY id_ LIMIT 1;"
      interval: 30s
      timeout: 20s
      retries: 5
      start_period: 1200s
    ports:
      - "3306:3306"
```

Docker 上安装依赖环境的 Docker Compose 脚本（使用 OceanBase）为：

```yaml
services:
##################################
##以下为依赖环境的容器############
##################################
  oceanbase: #齐鲁银行POC适配OB，保持root用户密码和端口不变，需要在启动容器后修改root用户密码为Kevin@GoodMan998，否则需要修改应用配置中的数据库连接信息
    image: oceanbase/oceanbase-ce:4.2.1
    container_name: ncpm2-oceanbase
    restart: on-failure:3
    ports:
      - "3306:2881"
  
  redis:
    image: redis:7.0.12
    container_name: ncpm2-redis
    restart: on-failure:3
    command: redis-server --requirepass good@Man
    volumes:
      - "/bucmt/docker/redis/data:/data" #风控决策引擎中的规则，都是加载到了redis的，需要恢复数据才能用“授信”中的风险探测
    healthcheck:
      test: ["CMD-SHELL", "redis-cli -h localhost -p 6379 -a good@Man ping | grep -q PONG"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 60s
    ports:
      - "6379:6379"

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.10.2
    container_name: ncpm2-elasticsearch
    restart: on-failure:3
    volumes:
      - "/bucmt/docker/elasticsearch/data:/usr/share/elasticsearch/data" #流程引擎中的审批记录存放在es中，如需要看之前的审批记录则需要恢复数据
    environment:
      - discovery.type=single-node
      - cluster.name=elasticsearch
    healthcheck:
      test: ["CMD-SHELL", "curl -s -f http://localhost:9200/ | grep -q '\"cluster_name\" : \"elasticsearch\"'"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 60s
    ports:
      - "9200:9200"
      - "9300:9300"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    mem_limit: 1g

  neo4j:
    image: neo4j:3.5.35-community
    container_name: ncpm2-neo4j
    restart: on-failure:3
    environment:
      - NEO4J_AUTH=neo4j/good@Man
      - NEO4J_dbms_memory_pagecache_size=1G
      - NEO4J_dbms_memory_heap_max__size=2G
    volumes:
      - "/bucmt/docker/neo4j/data:/data" #需要提前恢复数据库，客户管理中的“关联关系”图谱用到的演示数据，看文档操作
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- --user=neo4j --password=good@Man http://localhost:7474/db/data/ | grep -q '\"neo4j_version\"'"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 60s
    ports:
      - "7474:7474"
      - "7687:7687"

  consul:
    image: consul:1.15.2
    container_name: ncpm2-consul
    restart: on-failure:3
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:8500/v1/status/leader | grep -q '\"127.0.0.1:8300\"'"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 60s
    ports:
      - "8500:8500"

  mongo:
    image: mongo:5.0.19
    container_name: ncpm2-mongo
    restart: on-failure:3
    healthcheck:
      test: ["CMD", "mongo", "--eval", "db.adminCommand('ping')"]
      interval: 20s
      timeout: 10s
      retries: 3
      start_period: 30s
    ports:
      - "27017:27017"

  nacos:
    image: nacos/nacos-server:2.0.2
    container_name: ncpm2-nacos
    network_mode: host #这个属性保证nacos的注册IP地址为主机地址（期望的），检查控制台"集群管理">"节点列表"中的地址和端口
    restart: on-failure:3
    environment:
      - MODE=standalone #使用内置的数据库：风控没有用到配置中心，所有没有初始数据，无需启动外部的MySQL数据库模式
    healthcheck:
      test: sh -c "curl -sS http://localhost:8848/nacos/actuator/health | grep 'UP' || exit 1"
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 60s

##################################
##前端微服务######################
##################################
  ncpm2-console: #前端微服务
    image: xprogrammer/ncpm2-console:v2.0.5.poc #从nginx:1.26.2-alpine-slim打包，配置gateway位置为192.168.137.70
    container_name: ncpm2-console
    restart: on-failure:3
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost/"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 60s
    ports:
      - "9100:9100"
      - "9101:9101"
      - "9102:9102"
      - "9103:9103"
      - "9104:9104"
      - "9105:9105"
      - "9201:9201"
      - "9202:9202"
      - "9203:9203"
      - "9204:9204"
      - "9205:9205"
      - "9206:9206"
      - "9207:9207"
      - "9208:9208"
      - "9209:9209"
      - "9210:9210"
      - "9211:9211"
      - "9212:9212"
      - "9213:9213"
      - "9214:9214"
      - "9215:9215"
```

## 6 启停基础服务

执行如下命令完成基础环境的创建、启停和移除：

```bash
# 创建并启动容器
/root/compose/updown/up.sh
# 停止移除容器
/root/compose/updown/down.sh
# 启动容器
/root/compose/start.sh
# 停止容器
/root/compose/stop.sh
```

以上操作依赖于 `/root/compose/updown/ncpm2-poc-basenv.yml` 文件。

## 7 MySQL 快速恢复

在容器中使用 mysqldump 命令执行备份数据的命令：

```bash
# 进入容器的命令行
docker exec -it ncpm2-mysql sh
# 准备目录
mkdir ncpm
cd ncpm
# 备份数据库数据
mysqldump -uroot -pKevin@GoodMan998 --databases ijep8_sys_pro > ./1001-ijep8_sys_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases ijep8_priv_pro > ./1002-ijep8_priv_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases ijep8_bpm_pro > ./1003-ijep8_bpm_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases ijep8_sch_pro > ./1004-ijep8_sch_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases ijep8_demo_pro > ./1005-ijep8_demo_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases gcb_account_pro > ./1101-gcb_account_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases gcb_afterloan_pro > ./1102-gcb_afterloan_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases gcb_assess_pro > ./1103-gcb_assess_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases gcb_collateral_pro > ./1104-gcb_collateral_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases gcb_contract_pro > ./1105-gcb_contract_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases gcb_credit_pro > ./1106-gcb_credit_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases gcb_customer_pro > ./1107-gcb_customer_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases gcb_decision_pro > ./1108-gcb_decision_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases gcb_guarantee_pro > ./1109-gcb_guarantee_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases gcb_intellcenter_pro > ./1110-gcb_intellcenter_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases gcb_intellconfig_pro > ./1111-gcb_intellconfig_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases gcb_loan_pro > ./1112-gcb_loan_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases gcb_product_pro > ./1113-gcb_product_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases gcb_quota_pro > ./1114-gcb_quota_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases gcb_report_pro > ./1115-gcb_report_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases gcb_reportmock_pro > ./1116-gcb_reportmock_pro.sql
mysqldump -uroot -pKevin@GoodMan998 --databases dadp43 > ./1201-dadp43.sql
# 退出容器的sh
exit
# 拷贝容器内的数据到宿主机
docker cp ncpm2-mysql:/ncpm2 /root/
# 打包宿主机上的导出脚本备用
tar -czvf ncpm2-mysql-db-script.tar.gz ./ncpm2/
```

## 8 OceanBase 数据库

使用 Docker 安装 OceanBase 单节点数据库，官方的 Docker 镜像要求主机资源至少为 2C10G 配置。

```yaml
services:
  oceanbase:
    image: oceanbase/oceanbase-ce:4.2.1
    container_name: ncpm2-oceanbase
    restart: on-failure:3
    volumes:
      - "/bucmt/docker/ob:/root/ob"
      - "/bucmt/docker/obd:/root/.obd"
    ports:
      - "3306:2881"
```

> 经验证，volumes 挂接数据到外部目录，在容器重新创建后无法使用（容器启动失败），所以数据在容器内还是在容器外，针对 POC 测试环境或移植开发测试环境并不重要。

OceanBase 容器启动后，进入容器可查看集群启动情况：

```bash
# 查看容器启动日志
docker logs ncpm2-oceanbase
# 进入OB容器内，执行维护命令
docker exec -it ncpm2-oceanbase bash
# 查看OB集群情况
obd cluster list
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
+------------------------------------------------------------+
|                        Cluster List                        |
+-----------+------------------------------+-----------------+
| Name      | Configuration Path           | Status (Cached) |
+-----------+------------------------------+-----------------+
| obcluster | /root/.obd/cluster/obcluster | running         |
+-----------+------------------------------+-----------------+
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# 停止集群，后续关闭容器一定要先到容器内停止集群
obd cluster stop obcluster
# 启动集群
obd cluster start obcluster
# 查看集群信息
obd cluster display obcluster
# 连接到OB数据库，可执行SQL命令
obclient -h127.0.0.1 -P2881 -uroot -p'Kevin@GoodMan998' -Doceanbase -A
```

## 10 操作容器

需要临时往运行中的容器里添加内容：

```bash
# 进入运行运行中的ncpm2-console容器
docker exec -it ncpm2-console sh
# 拷贝容器中文件到宿主机
docker cp mycontainer:/path/in/container/ /path/to/local/
# 拷贝宿主机文件到容器中
docker cp /path/to/local/file.txt mycontainer:/path/in/container/
# 查看镜像信息
docker images
# 可检查镜像的具体信息，如果对latest的具体版本不清楚，可看镜像具体信息
docker image inspect <image_name_or_id>
# 在容器中做了操作，需要保存为新的镜像：比如格式化报告的基础依赖包和Playwright
docker ps -a
docker commit -m "说明" -a "作者" f7230060cc76 xprogrammer/ncpm2-report:2.1.9
docker save xprogrammer/ncpm2-report:2.1.9 -o xprogrammer/ncpm2-report-v2.1.9.tar
```

### 10.1 neo4j 恢复数据

neo4j 容器设定数据目录在宿主机中的 `/bucmt/docker/neo4j/data`  目录，恢复 neo4j 备份数据库文件必须先存在一个对应版本的 neo4j 数据库，然后才能将备份文件强制恢复到指定的数据库中。

- 如果是新环境则，宿主机中没有对应的 neo4j ，需要先创建一个容器，由容器在宿主机指定的目录下创建对应的数据库；
- 如果之前创建过容器，宿主机中 `/bucmt/docker/neo4j/data`  目录中就有 neo4j 的数据库。

> 当前给定的备份文件 neo4j.dump 中数据库用户是 neo4j，密码是 neo4j

```bash
# 1. 首先创建neo4j容器，使用--rm参数在后续容器停止时会自动删除这个容器，这样我们就得到了/bucmt/docker/neo4j/data下的数据库
docker run --rm -d --name neo4j --volume=/bucmt/docker/neo4j/data:/data neo4j:3.5.35-community
# 2. 停止neo4这个容器，由于使用了--rm参数所以会自动删除这个容器，如果没有使用--rm参数则使用docker rm -f neo4j命令删除
docker stop neo4j
# 3. 恢复数据库：将备份的neo4j.dump文件拷贝到/bucmt/docker/neo4j/data目录下
cp /root/neo4j.dump /bucmt/docker/neo4j/data/
# 4. 运行容器执行恢复命令，将容器内的/data/neo4j.dump备份文件（宿主机上映射进去的）恢复到neo4j数据库
docker run --interactive --tty --rm \
 --volume=/bucmt/docker/neo4j/data:/data \
 neo4j:3.5.35-community \
 neo4j-admin load --from=/data/neo4j.dump --database=graph.db --force
# 4. 这样我们就在宿主机的/bucmt/docker/neo4j/data目录下得到了恢复后的数据库
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
Warning: Some files inside "/data" are not writable from inside container. Changing folder owner to neo4j.
Done: 34 files, 1.386MiB processed.
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
# 5. 在docker compose文件中指定数据目录到提前恢复了数据库的位置，则可以使用恢复后的neo4j数据库（含客户中心的关联关系图）
# 6. 浏览器打开http://192.168.137.60:7474/，用neo4j/neo4j登录，然后修改密码为good@Man
```

### 10.2 Nacos 容器的设置

Nacos 在 compose 中启动时，必须使用主机网络，否则注册地址会变为容器内的 IP 地址，会导致其他服务无法注册上来：

```yaml
  nacos:
    image: nacos/nacos-server:2.0.2
    container_name: ncpm2-nacos
    network_mode: host #这个属性保证nacos的注册IP地址为主机地址（期望的）
    restart: on-failure:3
    environment:
      - MODE=standalone #使用内置的数据库：风控没有用到配置中心，没有初始数据
    healthcheck:
      test: sh -c "curl -sS http://localhost:8848/nacos/actuator/health | grep 'UP' || exit 1"
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 60s
```

如果发现 Nacos 注册异常，请在 web 控制台中检查 ："集群管理">"节点列表"中的地址和端口，是否和应用中的注册地址保持一致。

### 10.3 OceanBase 容器

OceanBase 的容器删除后，重建容器会导致外部数据不能用，所以测试环境不能使用外部数据存储，将数据存储在容器内部。采用创建容器后，再导入数据，供测试验证用。

```bash
# 进入OB容器内，执行维护命令
docker exec -it ncpm2-oceanbase bash
# 查看集群信息
obd cluster list
# 在容器内连接数据库，没有密码
obclient -h127.0.0.1 -P2881 -uroot@sys -p -c -A -Doceanbase
# 登录数据库后，修改root密码
alter user root identified by 'Kevin@GoodMan998';
# 退出ob客户端
exit
# 修改26行root_password的值为Kevin@GoodMan998，必须和root用户密码同步修改，否则数据库连接不上集群就起不来
vi /root/.obd/cluster/obcluster/config.yaml
# 停止集群，后续关闭容器一定要先到容器内停止集群
obd cluster stop obcluster
# 启动集群
obd cluster start obcluster

# Windows工作机上的MySQL命令行连接OB数据库
mysql -h192.168.137.60 -uroot -pKevin@GoodMan998 -P3306
# 导入数据，大概会花费15分钟
source d://temp/ijep8_sys_pro.sql;
source d://temp/ijep8_priv_pro.sql;
source d://temp/ijep8_bpm_pro.sql;
source d://temp/ijep8_sch_pro.sql;
source d://temp/ijep8_demo_pro.sql;
source d://temp/gcb_account_pro.sql;
source d://temp/gcb_afterloan_pro.sql;
source d://temp/gcb_assess_pro.sql;
source d://temp/gcb_collateral_pro.sql;
source d://temp/gcb_contract_pro.sql;
source d://temp/gcb_credit_pro.sql;
source d://temp/gcb_customer_pro.sql;
source d://temp/gcb_decision_pro.sql;
source d://temp/gcb_guarantee_pro.sql;
source d://temp/gcb_intellcenter_pro.sql;
source d://temp/gcb_intellconfig_pro.sql;
source d://temp/gcb_loan_pro.sql;
source d://temp/gcb_product_pro.sql;
source d://temp/gcb_quota_pro.sql;
source d://temp/gcb_report_pro.sql;
source d://temp/gcb_reportmock_pro.sql;
source d://temp/dadp43.sql;
# 在Windows工作机上使用Navcat查看数据库情况
# 数据导入完成后，修改ijep8_sys_pro库sys_app_manage表中FRONT_PORT_字段为前端地址192.168.137.60
```

如果编排到 Docker Compose 中，可使用 stop 停止容器，来停止 OceanBase 的服务。

## 11 风控部分

信贷 2.0 中集成的风控决策引擎，因为使用的是标准的 MySQL 语法，可以直接使用 OceanBase 数据库。

其使用了 Redis 存储风控规则，数据在 Redis 恢复文件的 10 号数据库中，注意修改配置（当前配置文件就在 10 号库）文件。

启动 4 个后端服务 + 1 个前端服务（tomcat）后，访问地址为：[http://192.168.137.90:8080/](http://192.168.137.90:8080/)，控制台没有用户名和密码。

访问 [http://192.168.137.90:8080/#/model-server/manager](http://192.168.137.90:8080/#/model-server/manager)（模型服务超市>模型服务管理）选择第 1 个模型（贷易通申请金额服务），点击”操作>测试“，如能正确返回”调用成功“，表示决策引擎部署和数据恢复成功。

在信贷系统中的“公司授信”中选择一家公司编辑后点击“风险探测”，能正确提示风险表示和 NCPm 2.0 对接成功。

## 12 智能报告

智能报告依赖 playwright，获取 playwright 的离线包，需要 node 环境：

```bash
# 安装node：https://npmmirror.com/mirrors/node/v20.18.0/node-v20.18.0-linux-arm64.tar.xz 下载对应的安装包
tar -xJf node-v20.18.0-linux-arm64.tar.xz
mv node-v20.18.0-linux-arm64 /usr/local/nodejs
ln -s /usr/local/nodejs/bin/node /usr/local/bin/node
ln -s /usr/local/nodejs/bin/npm /usr/local/bin/npm
ln -s /usr/local/nodejs/bin/npx /usr/local/bin/npx
node -v
npm -v
npx -v
# 加快下载速度，使用腾讯云的npm镜像网站
npm config set registry https://mirrors.cloud.tencent.com/npm
# 随意找个目录安装playwright
mkdir playwright
cd playwright
npm init playwright@latest
# windows下初始化后，在这个目录下得到离线包：C:\Users\Kevin\AppData\Local\ms-playwright
# linux下初始化后，在这个目录下得到离线包：/root/.cache/
# 离线包：npx playwright install
# 依赖包：npx playwright install-deps（只适用于ubuntu）
# 下载操作系统依赖离线安装包
yum install libstdc++ libgomp alsa-lib atk cairo cups-libs dbus-glib gtk3 pango --downloadonly --downloaddir=/root/x
```

观察其安装过程，后续可直接从对应地址提取安装包：

```bash
Downloading browsers (npx playwright install)…
BEWARE: your OS is not officially supported by Playwright; downloading fallback build for ubuntu20.04-arm64.
Downloading Chromium 130.0.6723.31 (playwright build v1140) from https://playwright-akamai.azureedge.net/builds/chromium/1140/chromium-linux-arm64.zip
169.4 MiB [====================] 100% 0.0s

Chromium 130.0.6723.31 (playwright build v1140) downloaded to /root/.cache/ms-playwright/chromium-1140
BEWARE: your OS is not officially supported by Playwright; downloading fallback build for ubuntu20.04-arm64.
Downloading FFMPEG playwright build v1010 from https://playwright.azureedge.net/builds/ffmpeg/1010/ffmpeg-linux-arm64.zip
1.6 MiB [====================] 100% 0.0s
FFMPEG playwright build v1010 downloaded to /root/.cache/ms-playwright/ffmpeg-1010
BEWARE: your OS is not officially supported by Playwright; downloading fallback build for ubuntu20.04-arm64.
Downloading Firefox 131.0 (playwright build v1465) from https://playwright.azureedge.net/builds/firefox/1465/firefox-ubuntu-20.04-arm64.zip
82 MiB [====================] 100% 0.0s
Firefox 131.0 (playwright build v1465) downloaded to /root/.cache/ms-playwright/firefox-1465
BEWARE: your OS is not officially supported by Playwright; downloading fallback build for ubuntu20.04-arm64.
Downloading Webkit 18.0 (playwright build v2083) from https://playwright.azureedge.net/builds/webkit/2083/webkit-ubuntu-20.04-arm64.zip
127.9 MiB [====================] 100% 0.0s
Webkit 18.0 (playwright build v2083) downloaded to /root/.cache/ms-playwright/webkit-2083
Playwright Host validation warning:
╔══════════════════════════════════════════════════════╗
║ Host system is missing dependencies to run browsers. ║
║ Missing libraries:                                   ║
║     libicudata.so.66                                 ║
║     libicui18n.so.66                                 ║
║     libicuuc.so.66                                   ║
║     libxslt.so.1                                     ║
║     libwoff2dec.so.1.0.2                             ║
║     libjpeg.so.8                                     ║
║     libwebpdemux.so.2                                ║
║     libwebp.so.6                                     ║
║     libenchant-2.so.2                                ║
║     libhyphen.so.0                                   ║
║     libflite.so.1                                    ║
║     libflite_usenglish.so.1                          ║
║     libflite_cmu_grapheme_lang.so.1                  ║
║     libflite_cmu_grapheme_lex.so.1                   ║
║     libflite_cmu_indic_lang.so.1                     ║
║     libflite_cmu_indic_lex.so.1                      ║
║     libflite_cmulex.so.1                             ║
║     libflite_cmu_time_awb.so.1                       ║
║     libflite_cmu_us_awb.so.1                         ║
║     libflite_cmu_us_kal16.so.1                       ║
║     libflite_cmu_us_kal.so.1                         ║
║     libflite_cmu_us_rms.so.1                         ║
║     libflite_cmu_us_slt.so.1                         ║
║     libpcre.so.3                                     ║
║     libgudev-1.0.so.0                                ║
║     libevdev.so.2                                    ║
║     libx264.so                                       ║
╚══════════════════════════════════════════════════════╝
```

为智能报告能力中心创建镜像：

```bash
# 使用eclipse-temurin:8-jdk-centos7打包智能报告能力中心镜像
# 使用主机网络，这样往cosult注册的地址才是主机地址，否则就会是容器内的地址导致服务无法调用

#1.使用eclipse-temurin:8-jdk-centos7打任意后台服务镜像后启动容器
docker run -d --name report --net host xprogrammer/gcb-center-report:v2.0.5.poc
#2.进入容器，提取该容器的ms-playwright依赖包：这些依赖包和初始镜像内的操作系统强以来，不通用
docker exec -it report sh
#3.CentOS7结束支持，官方yum源不能下载，需要替换成阿里源
vi /etc/yum.repos.d/CentOS-Base.repo
############################ 使用阿里云的镜像源替换yum下载地址##################
[base]
name=CentOS-$releasever - Base - mirrors.aliyun.com
baseurl=http://mirrors.aliyun.com/centos/$releasever/os/$basearch/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7
 
[updates]
name=CentOS-$releasever - Updates - mirrors.aliyun.com
baseurl=http://mirrors.aliyun.com/centos/$releasever/updates/$basearch/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7
 
[extras]
name=CentOS-$releasever - Extras - mirrors.aliyun.com
baseurl=http://mirrors.aliyun.com/centos/$releasever/extras/$basearch/
gpgcheck=1
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7
 
[centosplus]
name=CentOS-$releasever - Plus - mirrors.aliyun.com
baseurl=http://mirrors.aliyun.com/centos/$releasever/centosplus/$basearch/
gpgcheck=1
enabled=0
gpgkey=http://mirrors.aliyun.com/centos/RPM-GPG-KEY-CentOS-7
############################ 使用阿里云的镜像源替换yum下载地址##################
# 清理
yum clean all
yum makecache
#4.下载依赖包
cd
mkdir x
yum install libstdc++ libgomp alsa-lib atk cairo cups-libs dbus-glib gtk3 pango --downloadonly --downloaddir=/root/x
exit
#5.将容器内下载的依赖包拷贝到宿主机
docker cp report:/root/x/ /root/docker/pack/20105-report/ms-playwright-depends
#6.参考下面的Dockerfile，制作镜像
```

制作“智能报告”能力中心镜像的 Dockerfile 文件内容：

```dockerfile
FROM eclipse-temurin:8-jdk-centos7

COPY net-tools/*.rpm .
RUN rpm -i *.rpm
RUN rm -f *.rpm

COPY ms-playwright-depends/*.rpm .
RUN rpm -i *.rpm
RUN rm -f *.rpm

RUN mkdir /opt/ms-playwright
COPY ms-playwright /opt/ms-playwright

RUN mkdir -p /usr/share/Fonts/
COPY fonts/*.* /usr/share/Fonts

RUN mkdir /opt/app
COPY gcb-center-report.jar /opt/app/gcb-center-report.jar
COPY application-report.yml /opt/app/application-report.yml
CMD ["java", "-jar", "/opt/app/gcb-center-report.jar", "--spring.config.location=/opt/app/application-report.yml"]
```

需要注意的是：智能报告工程中依赖 `ms-playwright` 的版本要设定为 `1.48.0`（对应 `chromium 1140`），其对应的 `driver-bundle-1.48.0.jar` 内才带有 `aarch64` 的 `node`，咱们信贷 2.0 的智能报告工程中依赖的版本为 `1.19.0`，并不包含 `aarch64` 的 `node`（是 `x86_64` 的） 所以不可能正常运行。

Playwright 的测试验证参考代码：

```java
package net.xprogrammer.demo;

import com.microsoft.playwright.Browser;
import com.microsoft.playwright.BrowserType;
import com.microsoft.playwright.Page;
import com.microsoft.playwright.Playwright;

import java.io.File;
import java.nio.file.Paths;
import java.util.HashMap;
import java.util.Map;

/**
 * https://playwright.dev/java/docs/intro
 * <dependency>
 * <groupId>com.microsoft.playwright</groupId>
 * <artifactId>playwright</artifactId>
 * <version>1.48.0</version>
 * </dependency>
 *
 * @author Kevin Zhang
 * @version 1.0
 * @since 2024-10-26
 */
public class PlaywrightEnvTest {
    public static void main(String[] args) {
        // 指定playwright cli（含node）存在的位置，否则会自动创建临时目录
        // 如不指定，则每次启动都会自动生成到C:\Users\Kevin\AppData\Local\Temp\playwright-java-3796585563596180501的临时目录（目录后面的数字是自动生成的）
        // 并从依赖的driver-bundle-1.48.0.jar中解压对应操作系统&CPU架构的node和使用到的packages（driver-bundle-1.48.0.jar\driver\win32_x64\）到临时目录
        String playwrightCliDir = "D:\\temp\\playwrightCliDir";
        // 只能通过环境变量的方式来指定playwright cli（含node）的路径
        System.setProperty("playwright.cli.dir", playwrightCliDir);
        // 指定chromium执行文件的具体路径，需要到可执行的文件，如chrome.exe
        // 否则playwright就会从https://playwright.azureedge.net/builds/chromium/1140/chromium-win64.zip下载对应操作系统&CPU架构的chromium
        // 并解压存放在C:\Users\xxx\AppData\Local\ms-playwright\chromium-1140下面
        String chromiumExecutablePath = "D:\\temp\\playwrightChromium\\chromium-1140\\chrome-win\\chrome.exe";

        Playwright.CreateOptions createOptions = new Playwright.CreateOptions();
        Map<String, String> map = new HashMap<>();
        // 跳过下载浏览器，如果值为0=下载
        map.put("PLAYWRIGHT_SKIP_BROWSER_DOWNLOAD", "1");
        createOptions.setEnv(map);

        try (Playwright playwright = Playwright.create(createOptions)) {
            BrowserType.LaunchOptions launchOptions = new BrowserType.LaunchOptions();
            launchOptions.setHeadless(true);
            launchOptions.setChannel("chrome");
            launchOptions.setExecutablePath(Paths.get(new File(chromiumExecutablePath).toURI()));

            // 创建chromium浏览器，使用指定位置的chrome.exe
            Browser browser = playwright.chromium().launch(launchOptions);
            Page page = browser.newPage();
            page.navigate("https://www.baidu.com");
            System.out.println(page.title());

            // 关闭浏览器
            browser.close();
        }
    }
}
```

> 以上代码可以用来简化环境部署验证。
